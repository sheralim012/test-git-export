{
    "start": [
        0, 
        0, 
        1000, 
        7000, 
        8000, 
        10000, 
        13000, 
        18000, 
        22000, 
        26000, 
        30000, 
        45000, 
        46000, 
        49000, 
        50000, 
        53000, 
        56000, 
        60000, 
        63000, 
        67000, 
        68000, 
        79000, 
        82000, 
        87000, 
        95000, 
        98000, 
        101000, 
        105000, 
        108000, 
        111000, 
        113000, 
        116000, 
        119000, 
        120000, 
        124000, 
        126000, 
        129000, 
        136000, 
        142000, 
        153000, 
        155000, 
        157000, 
        159000, 
        166000, 
        168000, 
        171000, 
        175000, 
        177000, 
        191000, 
        192000, 
        195000, 
        198000, 
        201000, 
        203000, 
        206000, 
        209000, 
        211000, 
        215000, 
        218000, 
        220000, 
        222000, 
        225000, 
        228000, 
        230000, 
        233000, 
        235000, 
        238000, 
        242000, 
        244000, 
        246000, 
        248000, 
        251000, 
        253000, 
        255000, 
        256000, 
        261000, 
        263000, 
        265000, 
        269000, 
        271000, 
        272000, 
        282000, 
        284000, 
        289000, 
        290000, 
        291000, 
        292000, 
        293000, 
        295000, 
        300000, 
        302000, 
        307000, 
        310000, 
        312000, 
        314000, 
        317000, 
        318000, 
        320000, 
        323000, 
        324000, 
        326000, 
        332000, 
        339000, 
        342000, 
        346000, 
        347000, 
        351000, 
        355000, 
        359000, 
        361000, 
        362000, 
        363000, 
        365000, 
        368000, 
        371000, 
        374000, 
        377000, 
        379000, 
        380000, 
        383000, 
        386000, 
        389000, 
        392000, 
        397000, 
        398000, 
        403000, 
        406000, 
        409000, 
        413000, 
        414000, 
        417000, 
        419000, 
        420000, 
        421000, 
        426000, 
        435000, 
        442000, 
        445000, 
        449000, 
        450000, 
        452000, 
        454000, 
        456000, 
        458000
    ], 
    "end": [
        0, 
        1000, 
        7000, 
        8000, 
        10000, 
        13000, 
        18000, 
        22000, 
        26000, 
        30000, 
        45000, 
        46000, 
        49000, 
        50000, 
        53000, 
        56000, 
        60000, 
        63000, 
        67000, 
        68000, 
        79000, 
        82000, 
        87000, 
        95000, 
        98000, 
        101000, 
        105000, 
        108000, 
        111000, 
        113000, 
        116000, 
        119000, 
        120000, 
        124000, 
        126000, 
        129000, 
        136000, 
        142000, 
        153000, 
        155000, 
        157000, 
        159000, 
        166000, 
        168000, 
        171000, 
        175000, 
        177000, 
        191000, 
        192000, 
        195000, 
        198000, 
        201000, 
        203000, 
        206000, 
        209000, 
        211000, 
        215000, 
        218000, 
        220000, 
        222000, 
        225000, 
        228000, 
        230000, 
        233000, 
        235000, 
        238000, 
        242000, 
        244000, 
        246000, 
        248000, 
        251000, 
        253000, 
        255000, 
        256000, 
        261000, 
        263000, 
        265000, 
        269000, 
        271000, 
        272000, 
        282000, 
        284000, 
        289000, 
        290000, 
        291000, 
        292000, 
        293000, 
        295000, 
        300000, 
        302000, 
        307000, 
        310000, 
        312000, 
        314000, 
        317000, 
        318000, 
        320000, 
        323000, 
        324000, 
        326000, 
        332000, 
        339000, 
        342000, 
        346000, 
        347000, 
        351000, 
        355000, 
        359000, 
        361000, 
        362000, 
        363000, 
        365000, 
        368000, 
        371000, 
        374000, 
        377000, 
        379000, 
        380000, 
        383000, 
        386000, 
        389000, 
        392000, 
        397000, 
        398000, 
        403000, 
        406000, 
        409000, 
        413000, 
        414000, 
        417000, 
        419000, 
        420000, 
        421000, 
        426000, 
        435000, 
        442000, 
        445000, 
        449000, 
        450000, 
        452000, 
        454000, 
        456000, 
        458000, 
        461000
    ], 
    "text": [
        "", 
        "Why is that significant?", 
        "Suppose our circuit contains T total in gates.", 
        "Really, that's ambiguous.", 
        "I don't mean T gates like a pi/8 rotation.", 
        "I mean like T is the number-- total number of gates.", 
        "And these gates might each be some arbitrary rotation.", 
        "And so I might have to approximate each one of them", 
        "using my little library of elementary gates.", 
        "So every time I do that, I'm going to incur some error.", 
        "So I need to approximate each one within error at most", 
        "1 over--", 
        "let's say, 1 over 3T.", 
        "So remember that hybrid argument--", 
        "that sort of triangle inequality argument from the first problem", 
        "set that said, if we had T gate each with error at most 1", 
        "over 3T, the total error will be at most 1/3.", 
        "So 1/3 is a slightly arbitrary number,", 
        "but it should be some constant less than 1.", 
        "So what is the cost--", 
        "so if epsilon is 1 to the 3T, then m is going to be order--", 
        "sorry log cubed of T.", 
        "And so instead of having T gates,", 
        "we get order T times log cubed T gates.", 
        "So the overhead is polylogarithmic.", 
        "", 
        "And so what this means is that if you have even only", 
        "a polynomial speed-up, like a Grover type speed-up,", 
        "that speed-up is only slightly eroded", 
        "by having to do this gate compilation.", 
        "You go from n to, instead of root n,", 
        "to root n times polylog n.", 
        "So you don't even lose--", 
        "even polynomial speed-ups are preserved by this.", 
        "And this, if you recall--", 
        "", 
        "so this T to T polylog T--", 
        "or maybe I should write, this polylog 1", 
        "over epsilon behavior, this also occurs in fault tolerant", 
        "computing so remember that was that with the overhead", 
        "we incurred for fault-tolerant quantum computing", 
        "for the threshold theorem.", 
        "So it's sort of the good kind of scaling with error.", 
        "Let me give you another example where this sort of overhead", 
        "occurs.", 
        "And it also occurs even on classical computers", 
        "when you're doing high precision arithmetic.", 
        "", 
        "So why is that?", 
        "Let's suppose I have real numbers between 0 and 1.", 
        "And I want to represent each of them", 
        "to within an accuracy of epsilon.", 
        "So how many bits do I need?", 
        "I need log 1 over epsilon bits, right?", 
        "So now, all of my floating point numbers", 
        "I'm representing with log 1 over epsilon bits.", 
        "And it turns out all the basic arithmetic operations,", 
        "the effort is polynomial in the number of bits.", 
        "So addition is basically linear the number of bits--", 
        "modulus in smaller terms.", 
        "The kind of naive multiplication algorithm", 
        "is quadratic in the number of bits.", 
        "Division is a little more than that.", 
        "So I have all of these basic operations that go polynomially", 
        "in the number of bits.", 
        "And the number of bits is log 1 over epsilon.", 
        "So my overhead to do arithmetic to precision epsilon", 
        "is polylog 1 over epsilon.", 
        "So when you see a polylog 1 over epsilon,", 
        "you can think of it kind of like the way", 
        "you have to pay for more precision on a computer.", 
        "It's kind of the good kind of scaling,", 
        "where you add one more bit of precision", 
        "and the error gets cut in half.", 
        "", 
        "What about poly 1 over epsilon?", 
        "Can anyone think of an example in algorithms", 
        "where we see this type of scaling?", 
        "It's kind of a much worse sort of scaling.", 
        "Where do we see this?", 
        "", 
        "We haven't exact-- we've only sort of seen it in this class.", 
        "So the place where it occurs, any answers?", 
        "Phase estimation.", 
        "Say that again.", 
        "Phase estimation.", 
        "Right.", 
        "So in phase estimation, if you want precision epsilon,", 
        "you have to run for a time that's like 1 over epsilon.", 
        "And so that one is a little bit subtle,", 
        "because if you can do e to the minus iHt, sometimes", 
        "the time to do that scales linearly with t.", 
        "And sometimes you can do it--", 
        "the time goes logarithmically with t.", 
        "In Shor's algorithm, it goes only logarithmically with t,", 
        "and you don't have this problem.", 
        "But if it's a Hamiltonian that corresponds", 
        "to some physical Hamiltonian, then it", 
        "does go linearly with t.", 
        "And yeah, and phase estimation does have that kind of scaling.", 
        "", 
        "So this is for phase estimation sometimes.", 
        "", 
        "Let me give you a more basic example where this comes up,", 
        "which is sampling.", 
        "", 
        "Suppose I have a coin which has a bias.", 
        "So its probability of heads is p, and tails is 1 minus p.", 
        "I want to figure out p.", 
        "So what do I do?", 
        "I flip it a bunch of times.", 
        "And I look at the mean--", 
        "how many times it had come up heads divided", 
        "by the total number of runs.", 
        "And the expectation of this is going to be p.", 
        "And the variance is going to go like 1 over the square root", 
        "of the number of coin tosses.", 
        "So if I turn this around and I say,", 
        "how many coin tosses do I need for error epsilon,", 
        "the answer is going to be 1 over epsilon squared.", 
        "So that's the error you get in sampling.", 
        "So sampling error goes like poly 1 over epsilon.", 
        "And that's because I can't just flip it one more time and get", 
        "one more bit of precision.", 
        "I just sort of get slightly better statistics.", 
        "But in general, I just have to flip it", 
        "1 over epsilon squared times.", 
        "So that's kind of a high level view of how", 
        "should things scale with error.", 
        "This one is like it's going down exponentially", 
        "with the amount of effort I put in.", 
        "Here, it's going down polynomially", 
        "with the effort I put in.", 
        "", 
        "So the upshot of Solovay-Kitaev is that the BQP", 
        "doesn't depend on gate set.", 
        "As long as it's a universal gate set,", 
        "any gate set will do for the definition of BQP.", 
        "Some might be more practical--", 
        "maybe my fault-tolerance scheme makes it easier", 
        "to do one rather than the other one.", 
        "But I can just pick the one I want", 
        "and use Solovay-Kitaev to compile to the ones", 
        ""
    ]
}